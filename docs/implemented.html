<!doctype html>
<html lang="en">
<meta charset="utf-8">
<title>knime2py — Implemented Nodes</title>
<style>
  body { font-family: system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif;
         padding: 24px; color: #222; background: #fff; }
  h1 { margin: 0 0 12px; font-size: 20px; }
  .meta { color: #666; margin: 0 0 18px; font-size: 13px; }
  table { border-collapse: collapse; width: 100%; }
  th, td { border: 1px solid #ddd; padding: 8px 10px; vertical-align: top; }
  th { background: #f6f6f6; text-align: left; }
  tr:nth-child(even) td { background: #fafafa; }
  code { background: #f3f3f3; padding: 1px 4px; border-radius: 4px; }
  th.num, td.num { text-align: right; width: 3.25em; color: #666; }
</style>
<body>
<h1>knime2py — Implemented Nodes</h1>
<p class="meta">This page lists the KNIME nodes currently supported for code generation.
For unsupported nodes, the generator produces a best-effort stub and TODOs to guide manual implementation.</p>
<table>
  <thead>
    <tr>
      <th class="num">#</th>
      <th>KNIME Node</th>
      <th>Module</th>
      <th>Notes</th>
    </tr>
  </thead>
  <tbody>
    <tr><td class="num">1</td><td>Color Manager</td><td><code>color_manager.py</code></td><td>KNIME color annotations are UI metadata and have no native representation in pandas;<br>we therefore forward the input table unchanged to all outputs.</td></tr>
    <tr><td class="num">2</td><td>Column Appender</td><td><code>column_appender.py</code></td><td>- Settings read: selected_rowid_mode, selected_rowid_table, selected_rowid_table_number<br>(base suffix defaults to &quot;_r&quot;; final suffix becomes f&quot;{base}{k}&quot; per right table).<br>- Alignment: IDENTICAL → index join; other modes → positional concat with reset index.</td></tr>
    <tr><td class="num">3</td><td>Column Filter</td><td><code>column_filter.py</code></td><td>Parsing heuristics: looks for &lt;config&gt; blocks whose keys contain &quot;include&quot;/&quot;exclude&quot;, numeric<br>index entries (&lt;entry key=&#x27;0&#x27; value=&#x27;Col&#x27;/&gt; ...), or name entries (&lt;entry key=&#x27;name&#x27; value=&#x27;Col&#x27;/&gt;).<br>Falls back to generic &quot;columns&quot; blocks if include/exclude buckets are absent. Duplicate names are<br>de-duplicated while preserving the first occurrence. If no includes/excludes are found, the node<br>is a passthrough. Excludes are dropped with errors=&#x27;ignore&#x27;.<br>Only explicit column-name lists are supported—pattern/type/regex-based selection is not implemented.<br>Depends on lxml for parsing and emits pandas-only code; relies on project utilities<br>(iter_entries, normalize_in_ports, etc.).</td></tr>
    <tr><td class="num">4</td><td>CSV Reader</td><td><code>csv_reader.py</code></td><td>pandas&gt;=1.5 recommended (nullable dtypes supported in dtype mapping).<br>Quote/escape are passed to pandas. If escapechar equals quotechar, we omit escapechar and rely<br>on double-quote parsing (avoids C-engine &quot;EOF inside string&quot; errors).<br>Dtype mapping is derived from table_spec_config_Internals; unknown types are left to inference.<br>Path resolution supports LOCAL and RELATIVE knime.workflow only; other FS types are not yet handled.<br>Robust NA/dtype handling:<br>- Treat &#x27;&#x27; and &#x27; &#x27; as missing on read (na_values=[&#x27;&#x27;, &#x27; &#x27;], keep_default_na=True, skipinitialspace=True)<br>- Read WITHOUT dtype=..., then coerce per-column:<br>* numeric targets (&#x27;Int64&#x27;, &#x27;Float64&#x27;) via pd.to_numeric(..., errors=&#x27;coerce&#x27;).astype(target)<br>* other types via .astype(target)</td></tr>
    <tr><td class="num">5</td><td>CSV Writer</td><td><code>csv_writer.py</code></td><td>pandas&gt;=1.5 recommended for consistent NA/nullable dtype handling.<br>Path resolution supports LOCAL absolute paths and RELATIVE knime.workflow; other FS types are not yet handled.<br>Directory creation is not automatic; ensure out_path.parent exists before writing.<br>Line terminator / quoting mode / doublequote / escapechar are not explicitly mapped unless present; pandas defaults apply.<br>File is overwritten by default; KNIME “append/overwrite” style flags are not implemented here.</td></tr>
    <tr><td class="num">6</td><td>Decision Tree Learner</td><td><code>decision_tree_learner.py</code></td><td>Pruning options (e.g., pruningMethod/Reduced Error Pruning) are not available in sklearn DT;<br>consider ccp_alpha for cost-complexity pruning if needed.<br>First-split constraints and binary nominal split settings are not supported by sklearn.<br>Feature importances are impurity-based (Gini/entropy); consider permutation importances if<br>you need model-agnostic measures.<br>Library expectations: pandas&gt;=1.5, numpy&gt;=1.23, scikit-learn&gt;=1.2 recommended.</td></tr>
    <tr><td class="num">7</td><td>Decision Tree Predictor</td><td><code>decision_tree_predictor.py</code></td><td>The estimator itself must be scikit-learn-like.<br>Scope: classification predictor only. Multi-output and regression variants are not handled</td></tr>
    <tr><td class="num">8</td><td>Equal Size Sampling</td><td><code>equal_size_sampling.py</code></td><td>Exact mode only: “Approximate” sampling is not implemented in this generator.<br>Requires pandas; scikit-learn is used only for resample() (no synthetic example generation).<br>Seed is used when provided; default fallback is 1 for deterministic output.<br>Order of rows after concatenation is re-sorted back to the original index.</td></tr>
    <tr><td class="num">9</td><td>Excel Reader</td><td><code>excel_reader.py</code></td><td>Covered mappings (KNIME → pandas):<br>• Path: LOCAL &amp; RELATIVE (knime.workflow) via resolve_reader_path()<br>• Sheet selection: sheet_selection ∈ {FIRST, NAME, INDEX} → sheet (0 | &#x27;name&#x27; | index)<br>• Header: table_contains_column_names + column_names_row_number → header (0-based) or None<br>• Column range: read_from_column/read_to_column → usecols=&quot;A:D&quot; (Excel A1-style column span)<br>• Row range: read_from_row/read_to_row → skiprows / nrows (best-effort)<br>• Dtypes: table_spec_config_Internals → dtype mapping (nullable pandas dtypes when possible)<br>• Replace empty strings with missings: advanced_settings.replace_empty_strings_with_missings</td></tr>
    <tr><td class="num">10</td><td>Excel Writer</td><td><code>excel_writer.py</code></td><td>- Only XLSX is supported (engine=&#x27;openpyxl&#x27;). Legacy XLS (xls) is not implemented.<br>- KNIME-style row-wise append into an existing sheet is not fully replicated. Pandas<br>does not support true “append to bottom” without custom openpyxl manipulation.<br>- We honor if_sheet_exists and header flags but do not append rows.<br>- Auto-size columns, print layout, formula evaluation, and “open file after exec”<br>are not supported.</td></tr>
    <tr><td class="num">11</td><td>Gradient Boosted Trees (Classification) Learner</td><td><code>gbt_learner.py</code></td><td>- Feature selection: use included_names if present; otherwise all numeric/boolean columns except<br>the target. Excluded_names are removed afterward. If no target is configured, the node is a<br>passthrough: bundle=None and empty outputs with an error note in the summary.<br>- Hyperparameters mapped: nrModels→n_estimators, learningRate→learning_rate, maxLevels<br>(-1/absent → default 3)→max_depth, minNodeSize→min_samples_split (≥2), minChildSize→min_samples_leaf (≥1),<br>dataFraction (0&lt;≤1)→subsample (stochastic GB), columnSamplingMode→max_features (None/&#x27;sqrt&#x27;/&#x27;log2&#x27;/fraction/int),<br>seed→random_state. Seed defaults to 1 for deterministic output.<br>- Unsupported/orthogonal flags: splitCriterion (trees in sklearn GBT have fixed criterion),<br>missingValueHandling (impute beforehand), useAverageSplitPoints, useBinaryNominalSplits,<br>isUseDifferentAttributesAtEachNode (no direct sklearn analog). These are noted and ignored.<br>- Outputs: port 1=model bundle (estimator, metadata), port 2=feature_importances_, port 3=summary.<br>- Dependencies: lxml for XML parsing; pandas/numpy for data handling; scikit-learn for modeling.</td></tr>
    <tr><td class="num">12</td><td>Gradient Boosted Trees (Classification) Predictor</td><td><code>gbt_predictor.py</code></td><td>- Bundle keys (if present): {&#x27;estimator&#x27;,&#x27;features&#x27;,&#x27;target&#x27;,&#x27;classes&#x27;,...}; falls back gracefully<br>to bare estimator and infers features if needed (raises KeyError if required columns are missing).<br>- Prediction column name: custom if configured, else &quot;Prediction (&lt;target&gt;)&quot;.<br>- Probabilities: adds per-class &quot;P (&lt;target&gt;=&lt;class&gt;)&lt;suffix&gt;&quot; when predict_proba is available; may<br>also append &quot;&lt;prediction&gt; (confidence)&quot; as max probability.<br>- Optional: append number of boosted estimators as &quot;&lt;prediction&gt; (models)&quot;.<br>- Ignored flag: &#x27;useSoftVoting&#x27; (not applicable to sklearn GBT).</td></tr>
    <tr><td class="num">13</td><td>Linear Correlation</td><td><code>linear_corellation.py</code></td><td>Settings honored (from settings.xml):<br>- include-list: included_names / excluded_names + enforce_option (EnforceInclusion/EnforceExclusion)<br>- pvalAlternative: TWO_SIDED | GREATER | LESS  (re-scales p from two-sided if SciPy is available)<br>- columnPairsFilter: COMPATIBLE_PAIRS | ALL_PAIRS (we compute numeric↔numeric only)</td></tr>
    <tr><td class="num">14</td><td>Logistic Regression Learner</td><td><code>logreg_learner.py</code></td><td>- Feature selection: use included_names if set; otherwise all numeric/boolean columns minus the<br>target; then remove excluded_names.<br>- Hyperparameter mapping: solver(KNIME→sklearn), maxEpoch→max_iter, epsilon→tol, seed→random_state.<br>Target reference category is recorded as metadata only (no sklearn equivalent).</td></tr>
    <tr><td class="num">15</td><td>Logistic Regression Predictor</td><td><code>logreg_predictor.py</code></td><td>- Bundle keys (if present): {&#x27;estimator&#x27;,&#x27;features&#x27;,&#x27;target&#x27;,&#x27;classes&#x27;,...}; falls back to a bare<br>estimator and infers features if absent (raises KeyError if required columns are missing).<br>- Prediction column name: custom if configured; otherwise &quot;Prediction (&lt;target&gt;)&quot;.<br>- Probabilities: when predict_proba exists, adds &quot;P (&lt;target&gt;=&lt;class&gt;)&lt;suffix&gt;&quot; columns.<br>- XML quirks: reads KNIME’s misspelled keys verbatim<br>(has_custom_predicition_name, include_probabilites, propability_columns_suffix).</td></tr>
    <tr><td class="num">16</td><td>Missing Value Handler</td><td><code>missing_value.py</code></td><td>- Integers: mean/median/mode fills are rounded and per-column recast to nullable Int64.<br>- Skip branches always contain an executable statement (pass) to avoid IndentationError.<br>- We never emit .fillna(None).</td></tr>
    <tr><td class="num">17</td><td>MLP Predictor</td><td><code>mlp_predictor.py</code></td><td>- Settings: &quot;change prediction&quot; (bool), &quot;prediction column name&quot; (string),<br>&quot;append probabilities&quot; (bool), &quot;class probability suffix&quot; (e.g., &quot;_AN&quot;).</td></tr>
    <tr><td class="num">18</td><td>Normalizer</td><td><code>normalizer.py</code></td><td>- Column selection: use included_names if set; else all numeric dtypes (Int*/int*/Float*/float*);<br>drop excluded_names afterward.<br>- Modes: MINMAX uses new-min/new-max (constant/empty columns map to new_min);<br>ZSCORE uses (x-mean)/std (zero std → 0.0).</td></tr>
    <tr><td class="num">19</td><td>One to Many (One-Hot Encoding)</td><td><code>one_to_many.py</code></td><td>- Column selection: parsed from model/columns2Btransformed with EnforceInclusion/EnforceExclusion<br>semantics, restricted to string-like dtypes (string/object/category).<br>- Naming: new columns are prefixed with the source column and &#x27;=&#x27; separator (e.g., &quot;Region=West&quot;)<br>to avoid collisions when different columns share the same category label.<br>- Missing values: not encoded (rows with NA get all zeros for that column’s dummies).<br>- removeSources: if true, drops the original columns after expansion.</td></tr>
    <tr><td class="num">20</td><td>Partitioning</td><td><code>partitioning.py</code></td><td>- Implementation: sklearn.model_selection.train_test_split; seed honored when provided.<br>- STRATIFIED: uses class_column; NaN treated as a separate class; falls back to non-stratified if<br>stratification is infeasible (e.g., tiny classes).<br>- RELATIVE: fraction is clamped to [0,1]. ABSOLUTE: train_size is an integer bounded by len(df).</td></tr>
    <tr><td class="num">21</td><td>Random Forest (Classification) Learner</td><td><code>random_forest_learner.py</code></td><td>- Feature selection: use included_names if provided; otherwise all numeric/boolean columns except<br>the target; excluded_names are removed afterward.<br>- Hyperparameter mapping: nrModels→n_estimators; maxLevels&gt;0→max_depth else None; minNodeSize→min_samples_split;<br>minChildSize→min_samples_leaf; isDataSelectionWithReplacement→bootstrap; dataFraction→max_samples<br>(only when bootstrap=True); columnSamplingMode/columnFractionPerTree/columnAbsolutePerTree plus<br>isUseDifferentAttributesAtEachNode→max_features (&#x27;sqrt&#x27;/&#x27;log2&#x27;/1.0/fraction/int); seed→random_state.<br>- Info-only flags (not applied in sklearn RF): splitCriterion, missingValueHandling,<br>useAverageSplitPoints, useBinaryNominalSplits; noted and ignored.</td></tr>
    <tr><td class="num">22</td><td>Random Forest (Classification) Predictor</td><td><code>random_forest_predictor.py</code></td><td>- Ports: In1=model bundle, In2=data table, Out1=predicted table.<br>- Bundle keys (if present): {&#x27;estimator&#x27;,&#x27;features&#x27;,&#x27;target&#x27;,&#x27;classes&#x27;,...}; falls back to a bare<br>estimator and infers features if absent (raises KeyError if required columns are missing).<br>- Prediction column name: custom if configured; otherwise &quot;Prediction (&lt;target&gt;)&quot;.<br>- Probabilities: when available, adds &quot;P (&lt;target&gt;=&lt;class&gt;)&lt;suffix&gt;&quot;; may also append<br>&quot;&lt;prediction&gt; (confidence)&quot; as max probability. Optional &quot;Model Count&quot; from n_estimators.<br>- &#x27;useSoftVoting&#x27; is informational; sklearn RandomForest averages probabilities by design.</td></tr>
    <tr><td class="num">23</td><td>ROC Curve</td><td><code>roc_curve.py</code></td><td>- Inputs: one table with a truth column and per-class probability columns.<br>- Column binding: uses configured target/positive class and selected probability columns; if none<br>are set, attempts to auto-detect KNIME-style columns like &quot;P (&lt;target&gt;=&lt;class&gt;)_LR&quot;. Configure<br>explicitly if your suffix differs (e.g., _RF, _GB).<br>- Output artifacts: saves &quot;roc_&lt;node_id&gt;.(png|svg)&quot; and &quot;roc_table_&lt;node_id&gt;.csv&quot; in CWD; figure<br>size from width/height (pixels at 100 DPI). Title/axis labels are honored from settings.<br>- Implementation: sklearn.metrics.roc_curve/auc for each probability series; matplotlib for<br>plotting; pandas/numpy for data handling.</td></tr>
    <tr><td class="num">24</td><td>Row Filter</td><td><code>row_filter.py</code></td><td>- If a predicate expects values but none are provided, that predicate is skipped.<br>- For EQUAL/NOT_EQUAL with multiple values, we use isin / ~isin.<br>- For string ops we normalize via .astype(&#x27;string&#x27;) and guard NA with na=False.</td></tr>
    <tr><td class="num">25</td><td>RProp MLP Learner</td><td><code>mlp_learner.py</code></td><td>- Mapping: classcol→target; hiddenlayer→#hidden layers; nrhiddenneurons→neurons per layer;<br>maxiter→max_iter; ignoremv→drop rows with NA in X/y; useRandomSeed/randomSeed→random_state.<br>- Topology: hidden_layer_sizes = [n_hidden_neurons] × n_hidden_layers.<br>- Implementation detail: scikit-learn has no RProp; uses MLPClassifier (solver=&#x27;adam&#x27;) as an<br>approximation.<br>- Features: all numeric/bool columns except target. If ignoremv=False, upstream imputation may be<br>required (sklearn MLP does not accept NaNs).</td></tr>
    <tr><td class="num">26</td><td>Rule Engine</td><td><code>rule_engine.py</code></td><td>- Supported rules: TRUE =&gt; &quot;out&quot;; $col$ &lt;op&gt; value =&gt; &quot;out&quot; with &lt;, &lt;=, &gt;, &gt;=, =, ==, !=;<br>$col$ LIKE &quot;pat&quot; (uses * as wildcard; converted to a regex). A trailing TRUE acts as default.<br>- Column output: append to a new column if configured; otherwise replace the specified column;<br>falls back to &quot;RuleResult&quot; when no name is provided.<br>- Literals: numeric strings are emitted as numbers; everything else is a quoted Python literal.<br>- Limitations: no AND/OR chaining, no between/in lists, no regex beyond LIKE→wildcard, and no<br>type coercion beyond basic string/number handling.</td></tr>
    <tr><td class="num">27</td><td>Scorer</td><td><code>scorer.py</code></td><td>- Columns: &#x27;first&#x27; → truth column, &#x27;second&#x27; → prediction column (default &quot;Prediction (&lt;truth&gt;)&quot;).<br>ignore.missing.values=true drops NA before scoring; false keeps NA (sklearn metrics may fail).<br>- Confusion matrix labels: union of values from truth and prediction in order of appearance.</td></tr>
    <tr><td class="num">28</td><td>SMOTE</td><td><code>smote.py</code></td><td>- Feature/target: uses all numeric/bool columns as features and the configured class/target.<br>- Methods:<br>• oversample_equal → sampling_strategy=&#x27;auto&#x27; (minorities up to majority)<br>• otherwise uses rate: (0,1] → target_n ≈ rate * majority_n; &gt;1 → target_n ≈ rate * minority_n<br>- kNN: k_neighbors is clamped to ≤ (minority_count - 1) to avoid imblearn errors.<br>- Fallbacks: if no target, no numeric features, single-class, or SMOTE raises, the original df<br>is returned unchanged.</td></tr>
    <tr><td class="num">29</td><td>Statistics (Extended)</td><td><code>statistics.py</code></td><td>- compute_median: bool → include Median in numeric stats<br>- filter_nominal_columns/included_names: list → which columns to treat as nominal<br>- num_nominal-values_output: int → cap of categories per nominal column for Port 3 (occurrence table)</td></tr>
    <tr><td class="num">30</td><td>String Manipulation (Multi Column)</td><td><code>string_mamipulatioin_mc.py</code></td><td>- Append vs Replace: APPEND_OR_REPLACE ∈ {&quot;APPEND_COLUMNS&quot;,&quot;REPLACE_COLUMNS&quot;}<br>* Append uses APPEND_COLUMN_SUFFIX (default &quot;_transformed&quot;)<br>- Missing handling: values are processed with pandas &#x27;string&#x27; dtype to preserve NA<br>- Abort flag (&quot;Abort execution on evaluation errors&quot;): when False, per-column exceptions are<br>swallowed; when True, exceptions raise and stop execution.</td></tr>
    <tr><td class="num">31</td><td>String to Number</td><td><code>string_to_number.py</code></td><td>- Column selection: taken from model/include/included_names (present columns only).<br>- Separators: supports custom decimal separator and optional thousands separator.<br>- Target type: inferred from parse_type/cell_class (DoubleCell→Float64, Int/Long→Int64).<br>- Error handling: if fail_on_error==True → raise on any parse issue; otherwise coerce to NA.<br>- Missing values: preserved (pandas NA) via pd.to_numeric(..., errors=&#x27;coerce&#x27;) when not failing.</td></tr>
    <tr><td class="num">32</td><td>SVM Learner</td><td><code>svm_learner.py</code></td><td>- Feature coefficients only exist for linear/separable cases; for non-linear kernels we emit an<br>empty coefficient table.<br>- Scaling is not applied here; if KNIME’s node performs internal scaling, replicate upstream.<br>- Random seed: SVC uses it for probability calibration; default to 1 for reproducibility.</td></tr>
    <tr><td class="num">33</td><td>SVM Predictor</td><td><code>svm_predictor.py</code></td><td>- Bundle keys (if present): {&#x27;estimator&#x27;,&#x27;features&#x27;,&#x27;target&#x27;,&#x27;classes&#x27;,...}; falls back to a bare<br>estimator and infers features if absent (raises KeyError if required columns are missing).<br>- Prediction column name: custom if &quot;change prediction&quot; is true and a name is provided;<br>otherwise &quot;Prediction (&lt;target&gt;)&quot;.<br>- Probabilities: when predict_proba exists, adds &quot;P (&lt;target&gt;=&lt;class&gt;)&lt;suffix&gt;&quot; columns.</td></tr>
    <tr><td class="num">34</td><td>Table View</td><td><code>table_view.py</code></td><td>This view node intentionally writes NO outputs to the workflow context – it only prints.</td></tr>
    <tr><td class="num">35</td><td>Value Lookup</td><td><code>value_lookup.py</code></td><td>Merge details:<br>- To avoid dtype mismatches we always cast join keys to pandas &#x27;string&#x27; dtype.<br>- If caseSensitive is False we compare lowercased string keys.<br>- We avoid name collisions by suffixing new columns with &quot;_lkp&quot; when needed.</td></tr>
  </tbody>
</table>
</body>
</html>
