# Auto-generated test for KNIME workflow "ISU_Master_test"
# Generated by test_gen.cli â€” do not hand-edit; re-generate from the source workflow.

import os
import subprocess
import sys
from pathlib import Path

from support import csv_compare 

# RTOL for models results comparison. 10% is good enough.
RTOL = 0.1

def test_roundtrip_isu_master_test(output_dir: Path):
    """
    Test the roundtrip conversion of the KNIME workflow "ISU_Master_test" to Python.

    This function verifies that the KNIME workflow can be successfully converted to a Python
    workbook and that the output CSV files generated by the workbook match the expected output.

    Args:
        output_dir (Path): The directory where the generated Python workbook and output CSVs will be stored.
    """
    repo_root = Path(__file__).resolve().parents[1]
    knime_proj = repo_root / "tests" / "data" / "ISU_Master_test"
    out_dir = output_dir  # provided by conftest.py fixture
    expected_dir = repo_root / "tests" / "data" / "data" / "ISU_Master_test"

    # Preconditions
    assert (knime_proj / "workflow.knime").exists(), f"Missing workflow.knime in {knime_proj}"
    assert expected_dir.exists(), f"Expected directory missing: {expected_dir}"

    expected_csvs = sorted(expected_dir.glob("*output.csv"))
    assert expected_csvs, f"No expected '*output.csv' files found in {expected_dir}. Contents: {[p.name for p in expected_dir.iterdir()]}"

    # 1) Generate Python workbook(s) only, no graphs
    cmd = [
        sys.executable, "-m", "knime2py",
        str(knime_proj),
        "--out", str(out_dir),
        "--graph", "off",
        "--workbook", "py",
    ]
    env = os.environ.copy()
    env["PYTHONPATH"] = str(repo_root / "src") + (os.pathsep + env["PYTHONPATH"] if env.get("PYTHONPATH") else "")
    gen = subprocess.run(cmd, capture_output=True, text=True, cwd=str(repo_root), env=env)
    assert gen.returncode == 0, f"CLI failed\nSTDOUT:\n{gen.stdout}\nSTDERR:\n{gen.stderr}"

    # 2) Locate a generated workbook script
    candidates = sorted(out_dir.glob("*_workbook.py"))
    assert candidates, f"No *_workbook.py generated in {out_dir}. Contents: {[p.name for p in out_dir.iterdir()]}"
    script = candidates[0]

    # 3) Run the generated workbook (cwd=out_dir so relative paths like ../!output/*.csv resolve correctly)
    run = subprocess.run([sys.executable, str(script)], cwd=str(out_dir), capture_output=True, text=True, env=env)
    assert run.returncode == 0, f"Workbook execution failed\nSTDOUT:\n{run.stdout}\nSTDERR:\n{run.stderr}"

    # 4) Compare each expected '*output.csv' with produced file of the same name
    produced_names = {p.name for p in out_dir.glob("*.csv")}
    assert produced_names, f"No produced CSVs in {out_dir}. Contents: {[p.name for p in out_dir.iterdir()]}"

    for exp in expected_csvs:
        produced = out_dir / exp.name
        assert produced.exists(), (
            f"Produced CSV not found for expected '{exp.name}'. "
            f"Produced CSVs: {sorted(produced_names)}"
        )
        csv_compare.compare_csv(produced, exp, rtol=RTOL)
