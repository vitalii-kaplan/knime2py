# Auto-generated test for KNIME workflow "ISU_Master_test_preparation"
# Generated by test_gen.cli â€” do not hand-edit; re-generate from the source workflow.

"""
Test the roundtrip generation and execution of the KNIME workflow "ISU_Master_test_preparation".

Overview
----------------------------
This module tests the conversion of a KNIME workflow into a Python workbook and verifies 
the correctness of the output CSV files generated by the workflow.

Runtime Behavior
----------------------------
Inputs:
- The module reads the KNIME workflow file and expects to find input DataFrames as defined 
  in the workflow.

Outputs:
- The generated Python workbook is executed, and the output CSV files are written to the 
  specified output directory. The expected output files are compared against the produced 
  files to ensure correctness.

Key algorithms or mappings:
- The module utilizes subprocess calls to execute the generated Python code and compares 
  the output CSV files using the `csv_compare` utility.

Edge Cases
----------------------------
The code handles scenarios such as missing workflow files, empty expected output directories, 
and ensures that the produced CSV files match the expected structure.

Generated Code Dependencies
----------------------------
The generated code requires external libraries such as pandas and csv_compare for data 
manipulation and comparison. These dependencies are required by the generated code, not 
this test module.

Usage
----------------------------
This module is typically invoked as part of a test suite for the knime2py project. 
An example of expected context access is:
```python
output_dir = Path("path/to/output")
```

Node Identity
----------------------------
This module tests the KNIME workflow identified by the factory ID associated with 
"ISU_Master_test_preparation".

Configuration
----------------------------
The module does not generate code based on `settings.xml`, but it relies on the 
presence of the KNIME workflow file in the specified directory.

Limitations / Not implemented
----------------------------
The module does not handle all possible edge cases related to workflow execution and 
assumes that the workflow is correctly configured.

References
----------------------------
For more information, refer to the KNIME documentation and the knime2py project 
repository.
"""

import os
import subprocess
import sys
from pathlib import Path

from support import csv_compare  # provides compare_csv(...) and RTOL

# Resolve RTOL: env K2P_RTOL overrides the library default
_env_rtol = os.environ.get("K2P_RTOL")
RTOL = float(_env_rtol) if _env_rtol is not None else csv_compare.RTOL

def test_roundtrip_isu_master_test_preparation(output_dir: Path):
    """
    Test the roundtrip generation and execution of the KNIME workflow 
    "ISU_Master_test_preparation". This function verifies that the workflow 
    can be successfully converted to a Python workbook and that the output 
    CSV files match the expected results.

    Args:
        output_dir (Path): The directory where the generated Python workbook 
                           and output CSV files will be stored.
    """
    repo_root = Path(__file__).resolve().parents[1]
    knime_proj = repo_root / "tests" / "data" / "ISU_Master_test_preparation"
    out_dir = output_dir  # provided by conftest.py fixture
    expected_dir = repo_root / "tests" / "data" / "data" / "ISU_Master_test_preparation"

    # Preconditions
    assert (knime_proj / "workflow.knime").exists(), f"Missing workflow.knime in {knime_proj}"
    assert expected_dir.exists(), f"Expected directory missing: {expected_dir}"

    expected_csvs = sorted(expected_dir.glob("*output.csv"))
    assert expected_csvs, f"No expected '*output.csv' files found in {expected_dir}. Contents: {[p.name for p in expected_dir.iterdir()]}"

    # 1) Generate Python workbook(s) only, no graphs
    cmd = [
        sys.executable, "-m", "knime2py",
        str(knime_proj),
        "--out", str(out_dir),
        "--graph", "off",
        "--workbook", "py",
    ]
    env = os.environ.copy()
    env["PYTHONPATH"] = str(repo_root / "src") + (os.pathsep + env["PYTHONPATH"] if env.get("PYTHONPATH") else "")
    gen = subprocess.run(cmd, capture_output=True, text=True, cwd=str(repo_root), env=env)
    assert gen.returncode == 0, f"CLI failed\nSTDOUT:\n{gen.stdout}\nSTDERR:\n{gen.stderr}"

    # 2) Locate a generated workbook script
    candidates = sorted(out_dir.glob("*_workbook.py"))
    assert candidates, f"No *_workbook.py generated in {out_dir}. Contents: {[p.name for p in out_dir.iterdir()]}"
    script = candidates[0]

    # 3) Run the generated workbook (cwd=out_dir so relative paths like ../!output/*.csv resolve correctly)
    run = subprocess.run([sys.executable, str(script)], cwd=str(out_dir), capture_output=True, text=True, env=env)
    assert run.returncode == 0, f"Workbook execution failed\nSTDOUT:\n{run.stdout}\nSTDERR:\n{run.stderr}"

    # 4) Compare each expected '*output.csv' with produced file of the same name
    produced_names = {p.name for p in out_dir.glob("*.csv")}
    assert produced_names, f"No produced CSVs in {out_dir}. Contents: {[p.name for p in out_dir.iterdir()]}"

    for exp in expected_csvs:
        produced = out_dir / exp.name
        assert produced.exists(), (
            f"Produced CSV not found for expected '{exp.name}'. "
            f"Produced CSVs: {sorted(produced_names)}"
        )
        csv_compare.compare_csv(produced, exp, rtol=RTOL)
